{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfee58c7",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb583efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from load_qm9 import *\n",
    "from display_mol import *\n",
    "\n",
    "#load dataset\n",
    "ds = qm9_load_tfdata()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267f393f",
   "metadata": {},
   "source": [
    "## data management and preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a47fd9",
   "metadata": {},
   "source": [
    "### Moldecule dataloader for trainning in batchs of equal size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ee1d3b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset chargé : 133885 molécules\n",
      "Distribution des tailles : [    0     0     0     2     4     5    12    21    70   193   527  1150\n",
      "  2336  4259  7103 10646 14270 17394 17836 18336 12601 13189  4483  6362\n",
      "   713  1923    59   356     0    35]\n"
     ]
    }
   ],
   "source": [
    "ATOM_TYPES = [1, 6, 7, 8, 9]\n",
    "MAX_SIZE = 30 # max number of atoms per molecules\n",
    "\n",
    "\n",
    "class MoleculeDataset:\n",
    "    def __init__(self, tf_dataset):\n",
    "        self.ds = tf_dataset\n",
    "        self.molecules_list = list(self.ds.as_numpy_iterator()) # Convertir le dataset en liste pour pouvoir indexer\n",
    "        self.N = tf_dataset.reduce(0, lambda x, _: x + 1).numpy()\n",
    "        self.M_pdf = np.zeros(MAX_SIZE, dtype=np.int32)\n",
    "        self.molecules_by_size = {i: [] for i in range(MAX_SIZE)}\n",
    "        \n",
    "        self._index_molecules()\n",
    "        \n",
    "        print(f\"Dataset chargé : {self.N} molécules\")\n",
    "        print(f\"Distribution des tailles : {self.M_pdf}\")\n",
    "    \n",
    "\n",
    "    def _index_molecules(self):\n",
    "        for idx, example in enumerate(self.molecules_list):\n",
    "            n_atoms = example[1].shape[0]\n",
    "            self.M_pdf[n_atoms] += 1\n",
    "            self.molecules_by_size[n_atoms].append(idx)\n",
    "    \n",
    "    \n",
    "    def get_batch(self, batch_size): \n",
    "        \"\"\"\n",
    "        return generator that give infinite patchs with molecules of equal sizes\n",
    "        \"\"\" \n",
    "        valid_sizes = [M for M in range(MAX_SIZE) if self.M_pdf[M] >= batch_size]\n",
    "\n",
    "        valid_probs = np.array([self.M_pdf[M] for M in valid_sizes])\n",
    "        valid_probs = valid_probs / valid_probs.sum() \n",
    "        \n",
    "        while True:\n",
    "            M = np.random.choice(valid_sizes, p=valid_probs)\n",
    "            \n",
    "            available_indices = self.molecules_by_size[M]\n",
    "            \n",
    "            selected_indices = np.random.choice( # shuffle\n",
    "                    available_indices, \n",
    "                    size=batch_size, \n",
    "                    replace=False\n",
    "                )\n",
    "            \n",
    "            batch = [self.molecules_list[idx] for idx in selected_indices]\n",
    "            \n",
    "            yield self._collate_batch(batch)\n",
    "    \n",
    "    def _collate_batch(self, batch):\n",
    "        \"\"\"\n",
    "        Combine une liste de molécules en un batch.\n",
    "        \"\"\"\n",
    "        x = np.stack([mol[0] for mol in batch], axis=0)\n",
    "        y = np.stack([mol[1] for mol in batch], axis=0)\n",
    "        q = np.stack([mol[2] for mol in batch], axis=0)\n",
    "        \n",
    "        return [x, y, q]\n",
    "    \n",
    "    def get_epoch_batches(self, batch_size):\n",
    "        \"\"\"\n",
    "        Génère des batches pour une époque complète.\n",
    "        Chaque molécule apparaît exactement une fois par époque.\n",
    "        \"\"\"\n",
    "        all_batches = []\n",
    "        \n",
    "        for M in range(MAX_SIZE):\n",
    "            if self.M_pdf[M] == 0:\n",
    "                continue\n",
    "            \n",
    "            indices = self.molecules_by_size[M].copy()\n",
    "            \n",
    "            np.random.shuffle(indices)\n",
    "            \n",
    "            for i in range(0, len(indices), batch_size):\n",
    "                batch_indices = indices[i:i + batch_size]\n",
    "                if len(batch_indices) == batch_size:\n",
    "                    batch = [self.molecules_list[idx] for idx in batch_indices]\n",
    "                    all_batches.append(batch)\n",
    "        \n",
    "        np.random.shuffle(all_batches)\n",
    "        \n",
    "        for batch in all_batches:\n",
    "            yield self._collate_batch(batch)\n",
    "    \n",
    "\n",
    "molecules = MoleculeDataset(ds) # ~1min30\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e7bc5c66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(32, 9, 3), (32, 9), (32, 9)]\n",
      "[(32, 17, 3), (32, 17), (32, 17)]\n",
      "[(32, 16, 3), (32, 16), (32, 16)]\n",
      "[(32, 17, 3), (32, 17), (32, 17)]\n",
      "[(32, 21, 3), (32, 21), (32, 21)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n# Méthode 2 : Une epoch complète (chaque molécule vue exactement une fois)\\nprint(\"\\\\epoch complète:\")\\nfor epoch in range(2):\\n    print(f\"\\nÉpoque {epoch + 1}\")\\n    batch_count = 0\\n    for batch in molecules.get_epoch_batches(batch_size=32, shuffle=True):\\n        batch_count += 1\\n        if batch_count <= 3:  # Afficher les 3 premiers batches\\n            print(f\"  Batch {batch_count}: {batch[\\'N\\'][0]} atomes, {len(batch[\\'N\\'])} molécules\")\\n    print(f\"  Total: {batch_count} batches\")'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Génération infinie de batches (pour l'entraînement)\n",
    "batch_gen = molecules.get_batch(batch_size=32)\n",
    "\n",
    "for i in range(5):\n",
    "    batch = next(batch_gen)\n",
    "    print([i.shape for i in batch])\n",
    "\n",
    "\"\"\"\n",
    "# Méthode 2 : Une epoch complète (chaque molécule vue exactement une fois)\n",
    "print(\"\\epoch complète:\")\n",
    "for epoch in range(2):\n",
    "    print(f\"\\nÉpoque {epoch + 1}\")\n",
    "    batch_count = 0\n",
    "    for batch in molecules.get_epoch_batches(batch_size=32, shuffle=True):\n",
    "        batch_count += 1\n",
    "        if batch_count <= 3:  # Afficher les 3 premiers batches\n",
    "            print(f\"  Batch {batch_count}: {batch['N'][0]} atomes, {len(batch['N'])} molécules\")\n",
    "    print(f\"  Total: {batch_count} batches\")\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef2a13e",
   "metadata": {},
   "source": [
    "### one hot encoding for the molecule shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f4eb04dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.Size([32, 18, 3]), torch.Size([32, 18, 5]), torch.Size([32, 18])]\n",
      "[torch.Size([32, 18, 3]), torch.Size([32, 18]), torch.Size([32, 18])]\n"
     ]
    }
   ],
   "source": [
    "def one_hot_encode(batch):\n",
    "    x = torch.tensor(batch[0], dtype=torch.float32)\n",
    "    e = torch.tensor(batch[1], dtype=torch.long)\n",
    "    q = torch.tensor(batch[2], dtype=torch.float32)\n",
    "    \n",
    "    max_atom_type = max(ATOM_TYPES) + 1\n",
    "    lookup = torch.full((max_atom_type,), -1, dtype=torch.long)\n",
    "    \n",
    "    for idx, atom_type in enumerate(ATOM_TYPES):\n",
    "        lookup[atom_type] = idx\n",
    "    \n",
    "    y_indices = lookup[e]\n",
    "    \n",
    "    assert (y_indices >= 0).all(), \"Types d'atomes inconnus détectés!\"\n",
    "    \n",
    "    \n",
    "    e = torch.nn.functional.one_hot(y_indices, num_classes=len(ATOM_TYPES)).float()\n",
    "    \n",
    "    return [x, e, q]\n",
    "\n",
    "def one_hot_decode(batch):\n",
    "    x = batch[0].clone().detach()\n",
    "    e_onehot = batch[1].clone().detach()\n",
    "    q = batch[2].clone().detach()\n",
    "    \n",
    "    e_indices = torch.argmax(e_onehot, dim=-1)  # (batch_size, n_atoms)\n",
    "    atom_types_tensor = torch.tensor(ATOM_TYPES, dtype=torch.long)\n",
    "    e = atom_types_tensor[e_indices]\n",
    "    \n",
    "    return [x, e, q]\n",
    "\n",
    "\n",
    "\n",
    "def one_hot_decode_stochastic(batch, temperature=1.0):\n",
    "    x = batch[0].clone().detach()\n",
    "    e_soft = batch[1].clone().detach()\n",
    "    q = batch[2].clone().detach()\n",
    "    \n",
    "    # Option 2: Sampling selon les probabilités (stochastic)\n",
    "    e_probs = torch.nn.functional.softmax(e_soft / temperature, dim=-1)\n",
    "    e_indices = torch.multinomial(\n",
    "        e_probs.view(-1, e_probs.size(-1)), \n",
    "        num_samples=1\n",
    "    ).view(e_probs.shape[:-1])\n",
    "    \n",
    "    atom_types_tensor = torch.tensor(ATOM_TYPES, dtype=torch.long)\n",
    "    e = atom_types_tensor[e_indices]\n",
    "    \n",
    "    return [x, e, q]\n",
    "    \n",
    "\n",
    "mol = one_hot_encode(next(batch_gen))   \n",
    "print([e.shape for e in mol])\n",
    "print([e.shape for e in one_hot_decode(mol)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772c71b5",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3d1f74ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.76224422454834, 'loss_x': 4.501723289489746, 'loss_e': 0.6904703378677368, 'loss_q': 0.8790343403816223}\n",
      "{'loss': nan, 'loss_x': nan, 'loss_e': nan, 'loss_q': nan}\n",
      "{'loss': nan, 'loss_x': nan, 'loss_e': nan, 'loss_q': nan}\n",
      "{'loss': nan, 'loss_x': nan, 'loss_e': nan, 'loss_q': nan}\n",
      "{'loss': nan, 'loss_x': nan, 'loss_e': nan, 'loss_q': nan}\n",
      "{'loss': nan, 'loss_x': nan, 'loss_e': nan, 'loss_q': nan}\n",
      "{'loss': nan, 'loss_x': nan, 'loss_e': nan, 'loss_q': nan}\n",
      "{'loss': nan, 'loss_x': nan, 'loss_e': nan, 'loss_q': nan}\n",
      "{'loss': nan, 'loss_x': nan, 'loss_e': nan, 'loss_q': nan}\n",
      "{'loss': nan, 'loss_x': nan, 'loss_e': nan, 'loss_q': nan}\n"
     ]
    }
   ],
   "source": [
    "class UltraMagaDiffusion(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UltraMagaDiffusion, self).__init__()\n",
    "        self.T = 10\n",
    "        s = 1e-5\n",
    "        self.alpha = [(1-2*s)*(1 - (t/self.T))+s for t in range(self.T+1)]\n",
    "        self.omega = [1-alpha**2 for alpha in self.alpha]\n",
    "        self.L = 9\n",
    "        self.lr = 1e-4\n",
    "        self.num_class = len(ATOM_TYPES)\n",
    "\n",
    "        self.init_weight()\n",
    "    \n",
    "    def init_weight(self):\n",
    "        self.phi_e = torch.nn.ModuleList()\n",
    "        self.phi_inf = torch.nn.ModuleList()\n",
    "        self.phi_x = torch.nn.ModuleList()\n",
    "        self.phi_h = torch.nn.ModuleList()\n",
    "\n",
    "        nf = self.num_class + 2  # +2 for atom charge and t/T\n",
    "\n",
    "        for l in range(self.L):\n",
    "            self.phi_e.append(torch.nn.Sequential(\n",
    "                torch.nn.Linear(nf * 2 + 2, nf), \n",
    "                torch.nn.SiLU(),\n",
    "                torch.nn.Linear(nf, nf),\n",
    "                torch.nn.SiLU(),\n",
    "            ))\n",
    "\n",
    "            self.phi_inf.append(torch.nn.Sequential(\n",
    "                torch.nn.Linear(nf, 1),\n",
    "                torch.nn.Sigmoid(),\n",
    "            ))\n",
    "\n",
    "            self.phi_x.append(torch.nn.Sequential(\n",
    "                torch.nn.Linear(nf * 2 + 2, nf),\n",
    "                torch.nn.SiLU(),\n",
    "                torch.nn.Linear(nf, nf),\n",
    "                torch.nn.SiLU(),\n",
    "                torch.nn.Linear(nf, 1),\n",
    "            ))\n",
    "\n",
    "            self.phi_h.append(torch.nn.Sequential(\n",
    "                torch.nn.Linear(nf * 2, nf),\n",
    "                torch.nn.SiLU(),\n",
    "                torch.nn.Linear(nf, nf),\n",
    "            ))\n",
    "        \n",
    "    \n",
    "    def forward(self, mols, t):\n",
    "        (x, e, q) = mols \n",
    "        h = torch.cat([e, q[:, :, None], torch.ones_like(q)[:, :, None]*t[:, :, None]/self.T], dim=-1)\n",
    "        x0 = x.clone()\n",
    "        N = h.shape[1]\n",
    "        diff = x[:, :, None, :] - x[:, None, :, :]   # (B, N, N, 3)\n",
    "        a_ij = torch.sqrt(torch.sum(diff ** 2, dim=-1))[:, :, :, None]  # (B, N, N, 1)\n",
    "        for l in range(self.L):\n",
    "            diff = x[:, :, None, :] - x[:, None, :, :]   # (B, N, N, 3)\n",
    "            d_ij = torch.sqrt(torch.sum(diff ** 2, dim=-1))[:, :, :, None]  # (B, N, N, 1) distance squared matrix\n",
    "\n",
    "            # compute m_ij\n",
    "            h_i = h[:, :, None, :].expand(-1, N, N, -1)  # (B, N, N, d)\n",
    "            h_j = h[:, None, :, :].expand(-1, N, N, -1)  # (B, N, N, d)\n",
    "\n",
    "            features = torch.cat([h_i, h_j, d_ij, a_ij], dim=-1)  # (B, N, N, 2d+2)\n",
    "            m_ij = self.phi_e[l](features)  # (B, N, N, d)\n",
    "\n",
    "            # compute e_ij\n",
    "            e_ij = self.phi_inf[l](m_ij) # (B, N, N, 1)\n",
    "\n",
    "            # update x\n",
    "            weights = self.phi_x[l](features) * diff / (d_ij + 1.0)  # (B, N, N, 3)\n",
    "            x = x + weights.sum(dim=2)                          # (B, N, 3)\n",
    "\n",
    "            # update h\n",
    "            mask = ~torch.eye(N, dtype=bool)[None, :, :, None]  # (1, N, N, 1)\n",
    "            agg = (e_ij * mask * m_ij).sum(dim=2)   # (B, N, d)\n",
    "            h = h + self.phi_h[l](torch.cat([h, agg], dim=-1))   # (B, N, d)\n",
    "\n",
    "    \n",
    "        x = x - x0 # (B, N, 3)\n",
    "        x = x - torch.mean(x, axis=1)[:, None, :] # (B, 1, 3)\n",
    "        e, q = h[:, :, :self.num_class], h[:, :, self.num_class]\n",
    "        return (x, e, q)\n",
    "    \n",
    "\n",
    "    def training_step(self, batch, optimizer):\n",
    "        self.train()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        x, e, q = batch\n",
    "        B = x.shape[0]\n",
    "\n",
    "        t = torch.randint(1, self.T + 1, (B, 1)).float() # Random timestep per batch\n",
    "        eps_x = torch.randn_like(x) # (B, N, 3)\n",
    "        eps_e = torch.randn_like(e) # (B, N, D)\n",
    "        eps_q = torch.randn_like(q) # (B, N)\n",
    "\n",
    "        # Diffusion step: add noise to x0\n",
    "        alpha_t = torch.tensor(self.alpha)[t.long()].view(B, 1, 1)\n",
    "        omega_t = torch.sqrt(torch.tensor(self.omega))[t.long()].view(B, 1, 1)\n",
    "        x_t = alpha_t * x + omega_t * eps_x\n",
    "        e_t = alpha_t * e + omega_t * eps_e\n",
    "        q_t = alpha_t.squeeze(-1) * q + omega_t.squeeze(-1) * eps_q\n",
    "\n",
    "        # Predict denoised offset (model learns to predict ε)\n",
    "        eps_x_pred, eps_e_pred, eps_q_pred = self.forward((x_t, e_t, q_t), t)\n",
    "\n",
    "        # Reconstruction loss (denoising loss)\n",
    "        loss_x = torch.nn.functional.mse_loss(eps_x_pred, eps_x)\n",
    "        loss_e = torch.nn.functional.mse_loss(eps_e_pred, eps_e)\n",
    "        loss_q = torch.nn.functional.mse_loss(eps_q_pred, eps_q)\n",
    "\n",
    "        loss = loss_x + 0.25 * loss_e + 0.1 * loss_q # coef from the paper\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        return {\n",
    "            'loss': loss.item(),\n",
    "            'loss_x': loss_x.item(),\n",
    "            'loss_e': loss_e.item(),\n",
    "            'loss_q': loss_q.item(),\n",
    "        }\n",
    "\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def sample(self, batch_size, N):\n",
    "        self.eval()\n",
    "\n",
    "        # Initialize x_T from Gaussian noise\n",
    "        x = torch.randn(batch_size, N, 3)\n",
    "        e = torch.randn(batch_size, N, self.num_class)\n",
    "        q = torch.randn(batch_size, N)\n",
    "\n",
    "        for t in reversed(range(1, self.T + 1)):\n",
    "            t_tensor = torch.full((batch_size, 1), t).float()\n",
    "            dx, de, dq = self.forward((x, e, q), t_tensor)\n",
    "\n",
    "            # Compute coefficients\n",
    "            alpha_t = torch.tensor(self.alpha)[t].view(1, 1, 1)\n",
    "            omega_t = torch.tensor(self.omega)[t].view(1, 1, 1)\n",
    "            alpha_s = torch.tensor(self.alpha)[t-1].view(1, 1, 1)\n",
    "            omega_s = torch.tensor(self.omega)[t-1].view(1, 1, 1)\n",
    "\n",
    "            alpha_ts = alpha_t/alpha_s\n",
    "            omega_ts = omega_t - alpha_ts**2 * omega_s\n",
    "            omega_t_s = torch.sqrt(omega_ts * omega_s / omega_t)\n",
    "            # Reverse diffusion step\n",
    "            eps_x = torch.randn_like(x) if t > 1 else 0.0\n",
    "            eps_e = torch.randn_like(e) if t > 1 else 0.0\n",
    "            eps_q = torch.randn_like(q) if t > 1 else 0.0\n",
    "            x = x / alpha_s - omega_ts/(alpha_ts*torch.sqrt(omega_t)) * dx + omega_t_s * eps_x\n",
    "            e = e / alpha_s - omega_ts/(alpha_ts*torch.sqrt(omega_t)) * de + omega_t_s * eps_e\n",
    "            q = q / alpha_s.unsqueeze(-1) - (omega_ts/(alpha_ts*torch.sqrt(omega_t))).unsqueeze(-1) * dq + omega_t_s.unsqueeze(-1) * eps_q\n",
    "\n",
    "        return x, e, q\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = UltraMagaDiffusion()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=model.lr)\n",
    "batch_gen = molecules.get_batch(batch_size=32)\n",
    "\n",
    "for i in range(10):\n",
    "    batch = one_hot_encode(next(batch_gen))\n",
    "    logs = model.training_step(batch, optimizer)\n",
    "    print(logs)\n",
    "\n",
    "# Sampling\n",
    "#x_gen, e_gen, q_gen = model.sample(batch_size=8, N=9)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
